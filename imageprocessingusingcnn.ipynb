{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2333429,"sourceType":"datasetVersion","datasetId":1408532}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T21:48:06.817670Z","iopub.execute_input":"2024-12-22T21:48:06.818011Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Importing Libraries","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport numpy as np\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\n\nprint(\"Libraries imported successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Dataset Preperation","metadata":{}},{"cell_type":"markdown","source":"##  2.1 Classification","metadata":{}},{"cell_type":"code","source":"# Define paths for dataset\nsource_dir = \"/kaggle/input/animals-with-attributes-2/Animals_with_Attributes2/JPEGImages\"  \ntarget_dir = \"/kaggle/working/FilteredImages\"  \n\n# Select classes and limit images per class\nselected_classes = [\"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"]\nimages_per_class = 650\n\n# Create target directory and filter images\nos.makedirs(target_dir, exist_ok=True)\nfor class_name in selected_classes:\n    class_path = os.path.join(source_dir, class_name)\n    target_path = os.path.join(target_dir, class_name)\n    os.makedirs(target_path, exist_ok=True)\n    for i, file_name in enumerate(os.listdir(class_path)):\n        if i >= images_per_class:\n            break\n        full_file_name = os.path.join(class_path, file_name)\n        if os.path.isfile(full_file_name):\n            cv2.imwrite(os.path.join(target_path, file_name), cv2.imread(full_file_name))\n\nprint(\"Dataset prepared and balanced.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  2.2 Sizing and Normalization of Images","metadata":{}},{"cell_type":"code","source":"# Function to load and process images\ndef load_and_process_images(data_dir, image_size=(128, 128)):\n    images = []\n    labels = []\n    for class_name in os.listdir(data_dir):\n        class_path = os.path.join(data_dir, class_name)\n        if os.path.isdir(class_path):\n            for file_name in os.listdir(class_path):\n                file_path = os.path.join(class_path, file_name)\n                img = cv2.imread(file_path)\n                if img is not None:\n                    img_resized = cv2.resize(img, image_size)\n                    img_normalized = img_resized / 255.0\n                    images.append(img_normalized)\n                    labels.append(class_name)\n    return np.array(images), np.array(labels)\n\n# Load and process images\ndata_dir = target_dir\nX, y = load_and_process_images(data_dir)\nprint(f\"Dataset size: {X.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Define data augmentation generator\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\ndatagen.fit(X)\n\nprint(\"Data augmentation applied.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Creating the CNN Model","metadata":{}},{"cell_type":"code","source":"# Create a simple CNN model\nfrom tensorflow.keras.layers import Input\n\nmodel = Sequential([\n    Input(shape=(128, 128, 3)),\n    Conv2D(32, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(len(selected_classes), activation='softmax')\n])\n\nprint(\"CNN model created.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  5. Model Compilation and Training","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\n\n# Encode string labels to integers\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)  # String labels to integers\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\n# Convert integer labels to one-hot encoding\nnum_classes = len(np.unique(y_encoded))  # Total number of classes\ny_train_one_hot = to_categorical(y_train, num_classes=num_classes)\ny_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n\n# Create TensorFlow Dataset\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train_one_hot)).batch(32).shuffle(buffer_size=1024)\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test_one_hot)).batch(32)\n\n# Compile the model\nmodel.compile(\n    optimizer='adam',               # Optimization algorithm\n    loss='categorical_crossentropy', # Loss function\n    metrics=['accuracy']            # Evaluation metric\n)\n\n# Train the model\nhistory = model.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=20\n)\n\nprint(\"Model training completed.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Evaluating Model Performance","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot training and validation accuracy\nplt.figure(figsize=(12, 6))\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# Plot training and validation loss\nplt.figure(figsize=(12, 6))\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(validation_dataset)\nprint(f\"Test Accuracy: {test_accuracy:.2f}\")\nprint(f\"Test Loss: {test_loss:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Model Predictions","metadata":{}},{"cell_type":"code","source":"# Predict on test data\nimport numpy as np\n\n# Get one batch from the test dataset\nfor images, labels in validation_dataset.take(1):\n    predictions = model.predict(images)\n    predicted_classes = np.argmax(predictions, axis=1)\n    true_classes = np.argmax(labels.numpy(), axis=1)\n\n    # Visualize the results\n    plt.figure(figsize=(12, 12))\n    for i in range(9):\n        plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(f\"Predicted: {label_encoder.inverse_transform([predicted_classes[i]])[0]}\\nTrue: {label_encoder.inverse_transform([true_classes[i]])[0]}\")\n        plt.axis(\"off\")\n    plt.show()\n    break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Manipulated Test Set","metadata":{}},{"cell_type":"code","source":"# Function to manipulate images\ndef manipulate_images(images):\n    manipulated_images = []\n    for img in images:\n        manipulated = cv2.convertScaleAbs(img, alpha=1.5, beta=30)  # Increase brightness\n        manipulated_images.append(manipulated)\n    return np.array(manipulated_images)\n\n# Apply manipulation to the test set\nX_test_manipulated = manipulate_images(X_test)\nmanipulated_loss, manipulated_accuracy = model.evaluate(X_test_manipulated, y_test)\nprint(f\"Manipulated Test Accuracy: {manipulated_accuracy * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 9. Gray World Algorithm for Color Constancy\n","metadata":{}},{"cell_type":"code","source":"# Apply gray world algorithm for color constancy\ndef apply_gray_world(image):\n    avg_b, avg_g, avg_r = cv2.mean(image)[:3]\n    gray_value = (avg_b + avg_g + avg_r) / 3\n    scaling_factors = np.array([gray_value / avg_b, gray_value / avg_g, gray_value / avg_r])\n    corrected_image = image * scaling_factors\n    corrected_image = np.clip(corrected_image, 0, 255).astype(np.uint8)\n    return corrected_image\n\n# Apply color constancy to manipulated test set\nX_test_corrected = np.array([apply_gray_world(img) for img in X_test_manipulated])\n\n# Evaluate model with color-corrected test set\ncorrected_loss, corrected_accuracy = model.evaluate(X_test_corrected, y_test)\nprint(f\"Color Corrected Test Accuracy: {corrected_accuracy * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 10. Comparison of Results","metadata":{}},{"cell_type":"code","source":"# Compare results\nprint(\"Results Comparison:\")\nprint(f\"Original Test Accuracy: {test_accuracy * 100:.2f}%\")\nprint(f\"Manipulated Test Accuracy: {manipulated_accuracy * 100:.2f}%\")\nprint(f\"Color Corrected Test Accuracy: {corrected_accuracy * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 11. Creating README File\n","metadata":{}},{"cell_type":"code","source":"# Create README file\nreadme_content = \"\"\"\n# Image Classification Project\n\nThis project uses a subset of the Animals with Attributes 2 dataset to train a Convolutional Neural Network (CNN) for image classification. Key steps include:\n\n1. Preparing the dataset by selecting specific classes and balancing the number of images per class.\n2. Resizing and normalizing images to ensure consistency.\n3. Applying data augmentation techniques to enhance model robustness.\n4. Training a simple CNN model using TensorFlow/Keras.\n5. Evaluating the model on original, manipulated, and color-corrected test sets.\n\n## Dataset\n- Source: [Animals with Attributes 2](https://datasets.d2.mpi-inf.mpg.de/awa2/)\n\n## Steps\n1. Data Preparation\n2. Image Preprocessing\n3. Data Augmentation\n4. Model Training\n5. Evaluation and Analysis\n\n## Results\nThe model's accuracy is compared across original, manipulated, and color-corrected datasets to assess its performance under different conditions.\n\n\"\"\"\n\n# Save README to file\nwith open(\"/kaggle/working/README.md\", \"w\") as file:\n    file.write(readme_content)\n\nprint(\"README file created.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Vaktim kalmadigi icin istedigim sekilde sonuclayamadim, daha sonra duzeltecegim. ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}